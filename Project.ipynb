{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf32afd-9185-4128-9cb1-27b7234bc981",
   "metadata": {},
   "source": [
    "# Prediction of Heart Disease Occurence\n",
    "## Project Data Literacy, Winter term 2022/23\n",
    "\n",
    "Anna-Lena von Behren, 3892448  \n",
    "Jule Weber, 3891847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c08978-0957-401d-9128-312196722f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc49407-7eff-44ba-80dd-d75bbbea1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc3f80-54be-4b2e-975a-5e298fd11d6b",
   "metadata": {},
   "source": [
    "# 1. Data\n",
    "## 1.1 Data Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54317208-68a3-4e68-9ce5-2c2d9466a050",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"data/heart.csv\", sep=',', header=0)\n",
    "print_full(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fe3d96-b849-4fc9-a4a0-352638a562bc",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "+ Zero values in Cholesterol: Probably no measurements there  --> Missing values\n",
    "+ no NaNs  \n",
    "\n",
    "### Explanation of the Data:\n",
    "+ Age: Numeric variable describing the age of the subjects in years \n",
    "+ Sex: Nominal variable describing the sex of the subjects with M = male and F = female  \n",
    "+ ChestPainType: Nominal variable describing the type of chestpain the subjects felt (TA = Typical Angina, ATA = Atypical Angina, NAP = Non-Anginal Pain, ASY = Asymptomatic)\n",
    "+ RestingBP: Numeric variable of the resting blood pressure measured in mmHg\n",
    "+ Cholesterol: Numeric variable of serum cholesterol in mg/dl \n",
    "+ FastingBS: Binary variable of fasting blood sugar (1 = high FastingBS > 120mg/dl, 0 = normal blood sugar <= 120)\n",
    "+ RestingECG: Nominal variable of the resting electrocardiogram results (Normal = Normal, ST = having ST-T wave abnormality, LVH = showing probable or definite left ventricular hypertrophy) \n",
    "+ MaxHR:Numeric variable of the maximum heart rate\n",
    "+ ExerciseAngina: Nominal variable to indicate if exercise induced angina typical chest pain in the subjects (Y = yes, N = no)\n",
    "+ Oldpeak: Numeric variable of ST value in depression measured in an ECG\n",
    "+ ST\\_Slope: Nominal variable to indicate the type of slope of the peak exercise ST segment (Up = upsloping, Flat = flat, Down = downsloping)\n",
    "+ HeartDisease: Binary variable to indicate if the subject suffered from heart diesease (1 = heart disease, 0 = normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35563b-8279-479e-a2af-4b6e24c1819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de200eeb-cfef-41dc-92e0-4821f8beeb29",
   "metadata": {},
   "source": [
    "### Visualization of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ddb56-32a1-4a87-b65a-e2c8a4dec966",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = list(df.select_dtypes(include=['object']))\n",
    "num_data = list(df.select_dtypes(exclude=['object']))\n",
    "print(len(num_data))\n",
    "cmap=plt.cm.get_cmap('tab20b', 12).colors\n",
    "\n",
    "# categorical data\n",
    "\n",
    "fig1 = plt.figure(figsize=(8,4))\n",
    "fig1.suptitle(\"Distribution of categorical data\")\n",
    "\n",
    "gs1 = gridspec.GridSpec(2, 6)\n",
    "gs1.update(wspace = 2, hspace = 0.5)\n",
    "\n",
    "ax1 = plt.subplot(gs1[0, :2])\n",
    "df[cat_data[0]].value_counts().plot(kind='bar', xlabel=cat_data[0], ylabel='Count', rot=0, ax=ax1, color=cmap[0])\n",
    "\n",
    "ax2 = plt.subplot(gs1[0, 2:4])\n",
    "df[cat_data[1]].value_counts().plot(kind='bar', xlabel=cat_data[1], ylabel='Count', rot=0, ax=ax2, color=cmap[1])\n",
    "\n",
    "ax3 = plt.subplot(gs1[0, 4:6])\n",
    "df[cat_data[2]].value_counts().plot(kind='bar', xlabel=cat_data[2], ylabel='Count', rot=0, ax=ax3, color=cmap[2])\n",
    "\n",
    "ax4 = plt.subplot(gs1[1, :2])\n",
    "df[cat_data[3]].value_counts().plot(kind='bar', xlabel=cat_data[3], ylabel='Count', rot=0, ax=ax4, color=cmap[3])\n",
    "\n",
    "ax5 = plt.subplot(gs1[1, 2:4])\n",
    "df[cat_data[4]].value_counts().plot(kind='bar', xlabel=cat_data[4], ylabel='Count', rot=0, ax=ax5, color=cmap[4])\n",
    "\n",
    "\n",
    "# numerical data\n",
    "\n",
    "fig2 = plt.figure(figsize=(10,4))\n",
    "fig2.suptitle(\"Distribution of numerical data\")\n",
    "\n",
    "gs2 = gridspec.GridSpec(2, 8)\n",
    "gs2.update(wspace = 2, hspace = 0.5)\n",
    "\n",
    "ax6 = plt.subplot(gs2[0, :2])\n",
    "ax6.set_xlabel(str(num_data[0]))\n",
    "ax6.set_ylabel(\"Count\")\n",
    "df[num_data[0]].plot(kind='hist', ylabel='Count', rot=0, ax=ax6, color=cmap[5])\n",
    "\n",
    "ax7 = plt.subplot(gs2[0, 2:4])\n",
    "ax7.set_xlabel(str(num_data[1]))\n",
    "ax7.set_ylabel(\"Count\")\n",
    "df[num_data[1]].plot(kind='hist', xlabel=num_data[1], ylabel='Count', rot=0, ax=ax7, color=cmap[6])\n",
    "\n",
    "ax8 = plt.subplot(gs2[0, 4:6])\n",
    "ax8.set_xlabel(str(num_data[2]))\n",
    "ax8.set_ylabel(\"Count\")\n",
    "df[num_data[2]].plot(kind='hist', xlabel=num_data[2], ylabel='Count', rot=0, ax=ax8, color=cmap[7])\n",
    "\n",
    "ax9 = plt.subplot(gs2[0, 6:8])\n",
    "ax9.set_xlabel(str(num_data[3]))\n",
    "ax9.set_ylabel(\"Count\")\n",
    "df[num_data[3]].plot(bins=3, kind='hist', xlabel=num_data[3], ylabel='Count', rot=0, ax=ax9, color=cmap[8])\n",
    "\n",
    "ax10 = plt.subplot(gs2[1, :2])\n",
    "ax10.set_xlabel(str(num_data[4]))\n",
    "ax10.set_ylabel(\"Count\")\n",
    "df[num_data[4]].plot(kind='hist', xlabel=num_data[4], ylabel='Count', rot=0, ax=ax10, color=cmap[9])\n",
    "\n",
    "ax11 = plt.subplot(gs2[1, 2:4])\n",
    "ax11.set_xlabel(str(num_data[5]))\n",
    "ax11.set_ylabel(\"Count\")\n",
    "df[num_data[5]].plot(kind='hist', xlabel=num_data[5], ylabel='Count', rot=0, ax=ax11, color=cmap[10])\n",
    "\n",
    "ax12 = plt.subplot(gs2[1, 4:6])\n",
    "ax12.set_xlabel(str(num_data[6]))\n",
    "ax12.set_ylabel(\"Count\")\n",
    "df[num_data[6]].plot.hist(bins=3,xlabel=num_data[6], ylabel='Count', rot=0, ax=ax12, color=cmap[11])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9e920-f14f-4ac3-bb7a-2b311fa391d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Preprocessing\n",
    "\n",
    "**A.** Deal with missing data: \n",
    "+ Replace the zero entries in Cholesterol by the column's median to reduce its influence on the training as far as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a1606-6fd2-41f1-a671-841cb4863021",
   "metadata": {},
   "outputs": [],
   "source": [
    "chol_median = df['Cholesterol'].median()\n",
    "print(\"Median is\", chol_median)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Cholesterol'] == 0:\n",
    "        row['Cholesterol'] = chol_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f526fda3-fd00-4faa-a6a2-7ec384728893",
   "metadata": {},
   "source": [
    "**B.** Handle non-numerical data: Use `OrdinalEncode` from `sklearn.preprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e6ed7-8f2d-4169-8c8f-65ad60a35472",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "columnsToEncode = list(df.select_dtypes(include=['category','object']))\n",
    "print(\"Columns with non-numerical data:\", columnsToEncode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a35d5bf-97ff-4b45-a708-c75a6e55abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ordinal = df.copy()\n",
    "\n",
    "for feature in columnsToEncode:\n",
    "    df_ordinal[feature] = le.fit_transform(df_ordinal[feature])\n",
    "    \n",
    "df_ordinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33177490-52af-423d-96b6-edbf1d56e7c6",
   "metadata": {},
   "source": [
    "We now have ordinal numeric values for each category, so we can analyse the correlations between the features to decide whether to remove some of the features during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3edd2-ccf1-4555-9cdf-01ed9bbde58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 7))\n",
    "sns.heatmap(df_ordinal.corr(), annot=True, cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad8110-4f7d-488c-b9cc-b3b0b1d9839a",
   "metadata": {},
   "source": [
    "**B. Alternative**  \n",
    "Use One Hot Encoding so that the categorical property is maintained and one category not considered more important than another (pandas `get_dummies()` uses one-hot encoding as default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be7c4df-beaa-45ad-8467-f39d76c63aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = df.copy()\n",
    "\n",
    "for category in columnsToEncode:\n",
    "    df_onehot = pd.concat([df_onehot, pd.get_dummies(df_onehot[category], prefix=category,dummy_na=False)],axis=1).drop([category],axis=1)\n",
    "\n",
    "df_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d0288-98d1-44dd-9a97-694b84317a25",
   "metadata": {},
   "source": [
    "As this variant is the better choice for Machine Learning applications, we stick to `df_onehot` from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d00ba5-d575-49d9-b5a4-d4b56f6d7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = np.array(df_onehot.columns)\n",
    "\n",
    "cats_x = cats[cats == \"HeartDisease\"]\n",
    "cats_y = cats[cats != 'HeartDisease']\n",
    "X_df = df_onehot.drop(columns=cats_x)\n",
    "Y_df = df_onehot.drop(columns=cats_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c9de9e-9474-4881-b6d9-052ee9a13972",
   "metadata": {},
   "source": [
    "**C.** Normalisation and zero-centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b189c-61bb-4df8-9003-93f32dbdd9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = X_df.copy()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55256daf-c079-42db-8899-714527089457",
   "metadata": {},
   "source": [
    "## 1.3 Split data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d62699-4dfb-42c2-beba-50cae8314f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_df.to_numpy()\n",
    "y = np.ndarray.flatten(Y_df.to_numpy())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0373b4f5-79ee-43e6-b5b0-ed02c887a079",
   "metadata": {},
   "source": [
    "# 2. Linear Regression Models\n",
    "We will start with a very basic linear regression model, although having the expectation that this will not suffice our requirements. Nevertheless, we want a baseline model from which one we can improve during further steps.  \n",
    "\n",
    "## 2.1 Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b10e7-cbd6-4774-b46c-0dd96d1fa987",
   "metadata": {},
   "source": [
    "To choose the optimal alpha without considering the test performance, we select it via k-fold cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83315c9-7f0d-4274-bd7f-e782febf1959",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123456)\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "acc_score = []\n",
    "idx = 1\n",
    "\n",
    "for train_index , test_index in kf.split(X_train):\n",
    "\n",
    "    y_train_fold, y_test_fold = y_train[train_index] , y_train[test_index]\n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    \n",
    "    model = linear_model.RidgeClassifier(alpha=0.1*idx)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    acc_fold = model.score(X_test_fold, y_test_fold)\n",
    "    acc_score.append(acc_fold)\n",
    "    print(\"The training accuracy is\", round(acc_fold, 2) ,\"for alpha =\",round(0.1*idx, 2))\n",
    "    idx += 1\n",
    "    \n",
    "    \n",
    "best_alpha = (np.argmax(np.array(acc_score)) + 1) * 0.1\n",
    "print()\n",
    "print(\"The best accuracy was achieved by alpha =\",round(best_alpha,2), \"with a value of\",round(acc_score[np.argmax(np.array(acc_score))],2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6a36c-7e87-43ad-9dca-672240dcf72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.RidgeClassifier(alpha=best_alpha)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "acc_ridge = model.score(X_test, y_test)\n",
    "y_pred_ridge = model.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_pred_ridge, y_test)\n",
    "\n",
    "print(\"The resulting test accuracy for Ridge Regression is\", round(acc_ridge*100, 2), \"% with an MSE of\", round(mse_ridge, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11549b9-30f5-49ef-8354-7d924088cd64",
   "metadata": {},
   "source": [
    "Analyse the performance by looking at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284b13b-8b56-4500-880b-eebd49feeb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix_ridge = metrics.confusion_matrix(y_test, y_pred_ridge)\n",
    "\n",
    "class_names=[0,1]\n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "\n",
    "tick_marks = np.arange(len(class_names)) \n",
    "plt.xticks(tick_marks, class_names) \n",
    "plt.yticks(tick_marks, class_names) \n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix_ridge), annot=True, cmap=\"GnBu\" ,fmt='g') \n",
    "\n",
    "ax.xaxis.set_label_position(\"bottom\") \n",
    "\n",
    "plt.tight_layout() \n",
    "plt.title('Confusion matrix of Ridge Regression', y=1.01) \n",
    "plt.ylabel('Actual label') \n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b4db8-061c-4276-aae7-9738f27fdc65",
   "metadata": {},
   "source": [
    "## 2.2 Logistic Regression\n",
    "\n",
    "We choose the liblinear-solver, as this is said to be best for smaller datasets in the scikit-learn API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92eab7b-3b3c-4aa9-82b1-f0e79763423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = linear_model.LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "mse_log = mean_squared_error(y_pred_log, y_test)\n",
    "acc_log = log_model.score(X_test, y_test)\n",
    "\n",
    "print(\"The resulting test accuracy for Logistic Regression is\", round(acc_log*100, 2), \"% with an MSE of\", round(mse_log, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa8d335-7ba6-46cd-9020-aca954864c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix_log = metrics.confusion_matrix(y_test, y_pred_log)\n",
    "\n",
    "class_names=[0,1]\n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "\n",
    "tick_marks = np.arange(len(class_names)) \n",
    "plt.xticks(tick_marks, class_names) \n",
    "plt.yticks(tick_marks, class_names) \n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix_log), annot=True, cmap=\"GnBu\",fmt='g') #\"PuRd\"\n",
    "\n",
    "ax.xaxis.set_label_position(\"bottom\") \n",
    "\n",
    "plt.tight_layout() \n",
    "plt.title('Confusion matrix of Logistic Regression', y=1.01) \n",
    "plt.ylabel('Actual label') \n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b248ecca-37f5-416d-8941-16e475d8e860",
   "metadata": {},
   "source": [
    "## 2.3 Support Vector Classifier\n",
    "\n",
    "Due to the distributions of the input variables, we decided to use Gaussian kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043a55d-1952-4637-a5ec-2d83776dd232",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel=\"rbf\", C=0.1)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "mse_svc = mean_squared_error(y_pred_svc, y_test)\n",
    "acc_svc = log_model.score(X_test, y_test)\n",
    "\n",
    "print(\"The resulting test accuracy for Logistic Regression is\", round(acc_svc*100, 2), \"% with an MSE of\", round(mse_svc, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
